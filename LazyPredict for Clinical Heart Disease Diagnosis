{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":4843862,"sourceType":"datasetVersion","datasetId":2807336}],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/aruneembhowmick/lazypredict-for-clinical-heart-disease-diagnosis?scriptVersionId=209806188\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"import os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-11-26T20:22:58.522096Z","iopub.execute_input":"2024-11-26T20:22:58.523041Z","iopub.status.idle":"2024-11-26T20:22:58.562747Z","shell.execute_reply.started":"2024-11-26T20:22:58.522984Z","shell.execute_reply":"2024-11-26T20:22:58.561576Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/predicting-heart-disease-risk-using-clinical-var/Heart_Disease_Prediction.csv\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import pandas as pd\n\n!pip install lazypredict\nfrom lazypredict.Supervised import LazyClassifier\nfrom sklearn.model_selection import train_test_split\n\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-26T20:23:03.875928Z","iopub.execute_input":"2024-11-26T20:23:03.876318Z","iopub.status.idle":"2024-11-26T20:23:18.996025Z","shell.execute_reply.started":"2024-11-26T20:23:03.876282Z","shell.execute_reply":"2024-11-26T20:23:18.99486Z"},"_kg_hide-output":true},"outputs":[{"name":"stdout","text":"Collecting lazypredict\n  Downloading lazypredict-0.2.13-py2.py3-none-any.whl.metadata (12 kB)\nRequirement already satisfied: click in /opt/conda/lib/python3.10/site-packages (from lazypredict) (8.1.7)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from lazypredict) (1.2.2)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from lazypredict) (2.2.3)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from lazypredict) (4.66.4)\nRequirement already satisfied: joblib in /opt/conda/lib/python3.10/site-packages (from lazypredict) (1.4.2)\nRequirement already satisfied: lightgbm in /opt/conda/lib/python3.10/site-packages (from lazypredict) (4.2.0)\nRequirement already satisfied: xgboost in /opt/conda/lib/python3.10/site-packages (from lazypredict) (2.0.3)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from lightgbm->lazypredict) (1.26.4)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from lightgbm->lazypredict) (1.14.1)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->lazypredict) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->lazypredict) (2024.1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->lazypredict) (2024.1)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->lazypredict) (3.5.0)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->lazypredict) (1.16.0)\nDownloading lazypredict-0.2.13-py2.py3-none-any.whl (12 kB)\nInstalling collected packages: lazypredict\nSuccessfully installed lazypredict-0.2.13\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"def evaluateLazyClassifiers(data_path, features_to_ignore, features_for_regression):\n    data = pd.read_csv(data_path)\n    data = data.drop(features_to_ignore, axis = 1)\n    \n    features = data.drop(features_for_regression, axis = 1)\n    targets = data[features_for_regression]\n    features_train, features_test, targets_train, targets_test = train_test_split(features, targets, test_size = 0.2, random_state = 42)\n    \n    lazyClassifier = LazyClassifier(verbose = 0, ignore_warnings = True, custom_metric = None)\n    models, predictions = lazyClassifier.fit(features_train, features_test, targets_train, targets_test)\n    return models","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-26T20:23:23.847215Z","iopub.execute_input":"2024-11-26T20:23:23.847789Z","iopub.status.idle":"2024-11-26T20:23:23.854867Z","shell.execute_reply.started":"2024-11-26T20:23:23.847753Z","shell.execute_reply":"2024-11-26T20:23:23.853616Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"models = evaluateLazyClassifiers('/kaggle/input/predicting-heart-disease-risk-using-clinical-var/Heart_Disease_Prediction.csv', ['index'], ['Heart Disease'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-26T20:24:03.875918Z","iopub.execute_input":"2024-11-26T20:24:03.876417Z","iopub.status.idle":"2024-11-26T20:24:05.317031Z","shell.execute_reply.started":"2024-11-26T20:24:03.876375Z","shell.execute_reply":"2024-11-26T20:24:05.316091Z"},"_kg_hide-output":true},"outputs":[{"name":"stderr","text":"100%|██████████| 29/29 [00:01<00:00, 20.74it/s]","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Info] Number of positive: 99, number of negative: 117\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002903 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 232\n[LightGBM] [Info] Number of data points in the train set: 216, number of used features: 13\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.458333 -> initscore=-0.167054\n[LightGBM] [Info] Start training from score -0.167054\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"models","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-26T20:24:08.293434Z","iopub.execute_input":"2024-11-26T20:24:08.294562Z","iopub.status.idle":"2024-11-26T20:24:08.317048Z","shell.execute_reply.started":"2024-11-26T20:24:08.294505Z","shell.execute_reply":"2024-11-26T20:24:08.315989Z"}},"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"                               Accuracy  Balanced Accuracy ROC AUC  F1 Score  \\\nModel                                                                          \nLinearDiscriminantAnalysis         0.93               0.91    None      0.93   \nCalibratedClassifierCV             0.93               0.91    None      0.93   \nRidgeClassifierCV                  0.93               0.91    None      0.93   \nRidgeClassifier                    0.93               0.91    None      0.93   \nLinearSVC                          0.91               0.90    None      0.91   \nLogisticRegression                 0.91               0.90    None      0.91   \nGaussianNB                         0.91               0.89    None      0.91   \nSVC                                0.89               0.87    None      0.89   \nNuSVC                              0.89               0.87    None      0.89   \nQuadraticDiscriminantAnalysis      0.89               0.87    None      0.89   \nAdaBoostClassifier                 0.89               0.87    None      0.89   \nSGDClassifier                      0.85               0.85    None      0.85   \nNearestCentroid                    0.87               0.84    None      0.87   \nBernoulliNB                        0.87               0.84    None      0.87   \nExtraTreesClassifier               0.83               0.81    None      0.83   \nLabelSpreading                     0.81               0.80    None      0.81   \nLabelPropagation                   0.81               0.80    None      0.81   \nLGBMClassifier                     0.81               0.80    None      0.81   \nKNeighborsClassifier               0.81               0.79    None      0.81   \nPerceptron                         0.81               0.79    None      0.81   \nBaggingClassifier                  0.80               0.77    None      0.79   \nPassiveAggressiveClassifier        0.78               0.74    None      0.77   \nExtraTreeClassifier                0.74               0.74    None      0.74   \nRandomForestClassifier             0.76               0.73    None      0.76   \nDecisionTreeClassifier             0.69               0.69    None      0.69   \nDummyClassifier                    0.61               0.50    None      0.46   \n\n                               Time Taken  \nModel                                      \nLinearDiscriminantAnalysis           0.06  \nCalibratedClassifierCV               0.08  \nRidgeClassifierCV                    0.02  \nRidgeClassifier                      0.03  \nLinearSVC                            0.03  \nLogisticRegression                   0.03  \nGaussianNB                           0.03  \nSVC                                  0.02  \nNuSVC                                0.02  \nQuadraticDiscriminantAnalysis        0.03  \nAdaBoostClassifier                   0.12  \nSGDClassifier                        0.02  \nNearestCentroid                      0.02  \nBernoulliNB                          0.03  \nExtraTreesClassifier                 0.15  \nLabelSpreading                       0.11  \nLabelPropagation                     0.08  \nLGBMClassifier                       0.08  \nKNeighborsClassifier                 0.03  \nPerceptron                           0.02  \nBaggingClassifier                    0.05  \nPassiveAggressiveClassifier          0.03  \nExtraTreeClassifier                  0.02  \nRandomForestClassifier               0.18  \nDecisionTreeClassifier               0.02  \nDummyClassifier                      0.02  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Accuracy</th>\n      <th>Balanced Accuracy</th>\n      <th>ROC AUC</th>\n      <th>F1 Score</th>\n      <th>Time Taken</th>\n    </tr>\n    <tr>\n      <th>Model</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>LinearDiscriminantAnalysis</th>\n      <td>0.93</td>\n      <td>0.91</td>\n      <td>None</td>\n      <td>0.93</td>\n      <td>0.06</td>\n    </tr>\n    <tr>\n      <th>CalibratedClassifierCV</th>\n      <td>0.93</td>\n      <td>0.91</td>\n      <td>None</td>\n      <td>0.93</td>\n      <td>0.08</td>\n    </tr>\n    <tr>\n      <th>RidgeClassifierCV</th>\n      <td>0.93</td>\n      <td>0.91</td>\n      <td>None</td>\n      <td>0.93</td>\n      <td>0.02</td>\n    </tr>\n    <tr>\n      <th>RidgeClassifier</th>\n      <td>0.93</td>\n      <td>0.91</td>\n      <td>None</td>\n      <td>0.93</td>\n      <td>0.03</td>\n    </tr>\n    <tr>\n      <th>LinearSVC</th>\n      <td>0.91</td>\n      <td>0.90</td>\n      <td>None</td>\n      <td>0.91</td>\n      <td>0.03</td>\n    </tr>\n    <tr>\n      <th>LogisticRegression</th>\n      <td>0.91</td>\n      <td>0.90</td>\n      <td>None</td>\n      <td>0.91</td>\n      <td>0.03</td>\n    </tr>\n    <tr>\n      <th>GaussianNB</th>\n      <td>0.91</td>\n      <td>0.89</td>\n      <td>None</td>\n      <td>0.91</td>\n      <td>0.03</td>\n    </tr>\n    <tr>\n      <th>SVC</th>\n      <td>0.89</td>\n      <td>0.87</td>\n      <td>None</td>\n      <td>0.89</td>\n      <td>0.02</td>\n    </tr>\n    <tr>\n      <th>NuSVC</th>\n      <td>0.89</td>\n      <td>0.87</td>\n      <td>None</td>\n      <td>0.89</td>\n      <td>0.02</td>\n    </tr>\n    <tr>\n      <th>QuadraticDiscriminantAnalysis</th>\n      <td>0.89</td>\n      <td>0.87</td>\n      <td>None</td>\n      <td>0.89</td>\n      <td>0.03</td>\n    </tr>\n    <tr>\n      <th>AdaBoostClassifier</th>\n      <td>0.89</td>\n      <td>0.87</td>\n      <td>None</td>\n      <td>0.89</td>\n      <td>0.12</td>\n    </tr>\n    <tr>\n      <th>SGDClassifier</th>\n      <td>0.85</td>\n      <td>0.85</td>\n      <td>None</td>\n      <td>0.85</td>\n      <td>0.02</td>\n    </tr>\n    <tr>\n      <th>NearestCentroid</th>\n      <td>0.87</td>\n      <td>0.84</td>\n      <td>None</td>\n      <td>0.87</td>\n      <td>0.02</td>\n    </tr>\n    <tr>\n      <th>BernoulliNB</th>\n      <td>0.87</td>\n      <td>0.84</td>\n      <td>None</td>\n      <td>0.87</td>\n      <td>0.03</td>\n    </tr>\n    <tr>\n      <th>ExtraTreesClassifier</th>\n      <td>0.83</td>\n      <td>0.81</td>\n      <td>None</td>\n      <td>0.83</td>\n      <td>0.15</td>\n    </tr>\n    <tr>\n      <th>LabelSpreading</th>\n      <td>0.81</td>\n      <td>0.80</td>\n      <td>None</td>\n      <td>0.81</td>\n      <td>0.11</td>\n    </tr>\n    <tr>\n      <th>LabelPropagation</th>\n      <td>0.81</td>\n      <td>0.80</td>\n      <td>None</td>\n      <td>0.81</td>\n      <td>0.08</td>\n    </tr>\n    <tr>\n      <th>LGBMClassifier</th>\n      <td>0.81</td>\n      <td>0.80</td>\n      <td>None</td>\n      <td>0.81</td>\n      <td>0.08</td>\n    </tr>\n    <tr>\n      <th>KNeighborsClassifier</th>\n      <td>0.81</td>\n      <td>0.79</td>\n      <td>None</td>\n      <td>0.81</td>\n      <td>0.03</td>\n    </tr>\n    <tr>\n      <th>Perceptron</th>\n      <td>0.81</td>\n      <td>0.79</td>\n      <td>None</td>\n      <td>0.81</td>\n      <td>0.02</td>\n    </tr>\n    <tr>\n      <th>BaggingClassifier</th>\n      <td>0.80</td>\n      <td>0.77</td>\n      <td>None</td>\n      <td>0.79</td>\n      <td>0.05</td>\n    </tr>\n    <tr>\n      <th>PassiveAggressiveClassifier</th>\n      <td>0.78</td>\n      <td>0.74</td>\n      <td>None</td>\n      <td>0.77</td>\n      <td>0.03</td>\n    </tr>\n    <tr>\n      <th>ExtraTreeClassifier</th>\n      <td>0.74</td>\n      <td>0.74</td>\n      <td>None</td>\n      <td>0.74</td>\n      <td>0.02</td>\n    </tr>\n    <tr>\n      <th>RandomForestClassifier</th>\n      <td>0.76</td>\n      <td>0.73</td>\n      <td>None</td>\n      <td>0.76</td>\n      <td>0.18</td>\n    </tr>\n    <tr>\n      <th>DecisionTreeClassifier</th>\n      <td>0.69</td>\n      <td>0.69</td>\n      <td>None</td>\n      <td>0.69</td>\n      <td>0.02</td>\n    </tr>\n    <tr>\n      <th>DummyClassifier</th>\n      <td>0.61</td>\n      <td>0.50</td>\n      <td>None</td>\n      <td>0.46</td>\n      <td>0.02</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}